services:
  metrics-backend:
    build: .
    container_name: metrics-backend
    hostname: app-server
    restart: unless-stopped
    ports:
      - "192.168.189.101:3000:3000"
    security_opt:
      - apparmor:unconfined
    volumes:
    - /home/devops/backend/logs:/app/logs
    networks:
      - monitoring
    depends_on:
      elasticsearch:
        condition: service_healthy
      elasticsearch2:
        condition: service_healthy
    environment:
      - NODE_ENV=production
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - ELASTICSEARCH_URL2=http://elasticsearch2:9200
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    hostname: prometheus
    restart: unless-stopped
    ports:
      - "192.168.189.101:9090:9090"
    volumes:
      - ./configs/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./configs/alert_rules.yml:/etc/prometheus/alert_rules.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-admin-api'
    networks:
      - monitoring
    depends_on:
      elasticsearch:
        condition: service_healthy
      elasticsearch2:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    hostname: cadvisor
    restart: unless-stopped
    ports:
      - "192.168.189.101:8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    privileged: true
    devices:
      - /dev/kmsg
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    hostname: grafana
    restart: unless-stopped
    ports:
      - "192.168.189.101:3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    #logid
      - "logger.org.elasticsearch.xpack.transform=WARN"
      - "logger.org.elasticsearch.xpack.transform.transforms.TransformTask=ERROR"
      - "logger.org.elasticsearch.xpack.transform.transforms.TransformPersistentTasksExecutor=ERROR"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./configs/grafana/provisioning:/etc/grafana/provisioning
      - ./configs/grafana/dashboards:/var/lib/grafana/dashboards:ro
    networks:
      - monitoring
    depends_on:
      prometheus:
        condition: service_started
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    hostname: elasticsearch
    restart: unless-stopped
    environment:
      - node.name=elasticsearch
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=elasticsearch,elasticsearch2
      - cluster.initial_master_nodes=elasticsearch,elasticsearch2
      - bootstrap.memory_lock=true
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "192.168.189.101:9200:9200"
    networks:
      - monitoring
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 30
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 2.5G
        reservations:
          memory: 512M

  elasticsearch2:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch2
    hostname: elasticsearch2
    restart: unless-stopped
    environment:
      - node.name=elasticsearch2
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=elasticsearch,elasticsearch2
      - cluster.initial_master_nodes=elasticsearch,elasticsearch2
      - bootstrap.memory_lock=true
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch2-data:/usr/share/elasticsearch/data
    networks:
      - monitoring
    ports:
      - "192.168.189.101:9201:9200"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 30
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 2.5G
        reservations:
          memory: 512M

  elasticsearch-exporter:
    container_name: elasticsearch-exporter
    hostname: elasticsearch-exporter
    restart: unless-stopped
    image: prometheuscommunity/elasticsearch-exporter:latest
    ports:
      - 9114:9114
    command:
     - '--es.uri=http://elasticsearch:9200'
    networks:
      - monitoring
    mem_limit: 256m
    depends_on:
      elasticsearch:
        condition: service_healthy
      elasticsearch2:
        condition: service_healthy

  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: logstash
    hostname: logstash
    restart: unless-stopped
    ports:
      - "192.168.189.101:5044:5044"
      - "192.168.189.101:5000:5000/tcp"
      - "192.168.189.101:5000:5000/udp"
    volumes:
      - ./configs/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./configs/logstash/config:/usr/share/logstash/config:ro
    environment:
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    networks:
      - monitoring
    depends_on:
      elasticsearch:
        condition: service_healthy
      elasticsearch2:
        condition: service_healthy
      kibana:
        condition: service_healthy
      filebeat:
        condition: service_started
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9600/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1.5G
        reservations:
          memory: 512M

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kibana
    hostname: kibana
    restart: unless-stopped
    ports:
      - "192.168.189.101:5601:5601"
    volumes:
      - kibana-data:/usr/share/kibana/data
      - ./configs/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml:ro
    environment:
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false=value
    networks:
      - monitoring
    depends_on:
      elasticsearch:
        condition: service_healthy
      elasticsearch2:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 20
      start_period: 90s
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: filebeat
    hostname: filebeat
    restart: unless-stopped
    user: root
    command: ["filebeat", "-e", "-c", "/usr/share/filebeat/filebeat.yml"]
    labels:
      co.elastic.logs/enabled: "false"
    volumes:
      - ./configs/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /home/devops/backend/logs:/var/log/app:ro
      - /var/log:/var/log/host:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - monitoring
    depends_on:
      elasticsearch:
        condition: service_healthy
      elasticsearch2:
        condition: service_healthy
      kibana:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    hostname: node-exporter-app
    ports:
      - "9100:9100"
    volumes:
      - /home/devops/node_exporter_metrics:/textfile_collector
    command:
      - '--collector.textfile.directory=/textfile_collector'
    restart: always
    networks:
      - monitoring

volumes:
  prometheus-data:
  grafana-data:
  elasticsearch-data:
  elasticsearch2-data: 
  kibana-data:

networks:
  monitoring:
    driver: bridge